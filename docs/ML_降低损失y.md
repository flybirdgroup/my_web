---
id: ML2
title: 机器学习-- 2 降低损失
sidebar_label: Style Guide
---

[官方文档信息](https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach)

我们看美剧的时候,有一个叫做hot and cold的寻物游戏,在我们的游戏中，“隐藏的物品”就是最佳模型。刚开始，您会胡乱猜测（“ 的值为 0。”），等待系统告诉您损失是多少。然后，您再尝试另一种猜测（“ 的值为 0.5。”），看看损失是多少。哎呀，这次更接近目标了。实际上，如果您以正确方式玩这个游戏，通常会越来越接近目标。这个游戏真正棘手的地方在于尽可能高效地找到最佳模型。

![img](https://developers.google.com/machine-learning/crash-course/images/GradientDescentDiagram.svg)

我们通过特征和标签构建模型,通过模型执行分析,然后计算损失,然后再计算参数更新,调整模型,再执行分析,这样循环下次直到得到的模型是最佳模型

“模型”部分将一个或多个特征作为输入，然后返回一个预测 (y') 作为输出。为了进行简化，不妨考虑一种采用一个特征并返回一个预测的模型：

y = b + w1x1
我们应该为  和  设置哪些初始值？对于线性回归问题，事实证明初始值并不重要。我们可以随机选择值，不过我们还是选择采用以下这些无关紧要的值：
b = 0, w1 = 0

```
  y' = 0 + 0(10)
  y' = 0
```
图中的“计算损失”部分是模型将要使用的损失函数。假设我们使用平方损失函数。损失函数将采用两个输入值：

y'：模型对特征 x 的预测
y：特征 x 对应的正确标签。
最后，我们来看图的“计算参数更新”部分。机器学习系统就是在此部分检查损失函数的值，并为 b 和 w1 生成新值。现在，假设这个神秘的绿色框会产生新值，然后机器学习系统将根据所有标签重新评估所有特征，为损失函数生成一个新值，而该值又产生新的参数值。这种学习过程会持续迭代，直到该算法发现损失可能最低的模型参数。通常，您可以不断迭代，直到总体损失不再变化或至少变化极其缓慢为止。这时候，我们可以说该模型已收敛。